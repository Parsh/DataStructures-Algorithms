{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms Theory\n",
    "\n",
    "## Introduction to Algorithms\n",
    "\n",
    ">Algorithm is a step-by-step procedure, which defines a set of instructions to be executed in a certain order to get the desired output. Algorithms are generally created independent of underlying languages, i.e. an algorithm can be implemented in more than one programming language.\n",
    "\n",
    "\n",
    "![](./Images-Algorithms/AlgorithmAnalogy.png \"Program vs Algorithm\")\n",
    "Note: For more on models of computation (Random Access Machine and Pointer Machine) refer to the MIT 6.006 digital notes (Lecture 2).\n",
    "\n",
    "**Psuedocode:** Pseudo code is an informal high-level description of the operating principle of an algorithm. It uses the structural conventions of a normal programming language, but is intended for human reading rather than machine reading. As we know that all programming languages share basic code constructs like loops (for, while), flow-control (if-else), etc. These common constructs can be used, in psuedocode, to write an algorithm.\n",
    "\n",
    "**Fundamental Idea behind algorithm design:**\n",
    "![](./Images-Algorithms/FundamentalIdea.png \"Fundamental Idea in Algorithm Design\")\n",
    "Algorithmic Design Patterns like Divide and Conquer, Dynamic Programming and Greedy Algorithms uses this fundamental idea to design apt algorithms.\n",
    "\n",
    "\n",
    "\n",
    "**Categories of algorithms:**\n",
    "\n",
    "From the data structure point of view, following are some important categories of algorithms:\n",
    "\n",
    "- **Search** − Algorithm to search an item in a data structure.\n",
    "- **Insert** − Algorithm to insert item in a data structure.\n",
    "- **Update** − Algorithm to update an existing item in a data structure.\n",
    "- **Delete** − Algorithm to delete an existing item from a data structure.\n",
    "- **Sort** − Algorithm to sort items in a certain order.\n",
    "\n",
    "![](./Images-Algorithms/WhyAlgorithms.png )\n",
    "\n",
    "\n",
    "**Characteristics of an Algorithm:**\n",
    "\n",
    "Not all procedures can be called an algorithm. An algorithm should have the following characteristics:\n",
    "\n",
    ">**Input** − An algorithm should have 0 or more well-defined inputs.\n",
    "\n",
    ">**Output** − An algorithm should have 1 or more well-defined outputs, and should match the desired output.\n",
    "\n",
    ">**Unambiguous** − Algorithm should be clear and unambiguous. Each of its steps (or phases), and their inputs/outputs should be clear and must lead to only one meaning.\n",
    "\n",
    ">**Finiteness** − Algorithms must terminate after a finite number of steps, an infinite procedure isn't regarded as an algorithm.\n",
    "\n",
    ">**Feasibility** − Should be feasible with the available resources.\n",
    "\n",
    ">**Independent** − An algorithm should have step-by-step directions, which should be independent of any programming code.\n",
    "\n",
    "Reference: [Data Structures and Algorithms](https://www.tutorialspoint.com/data_structures_algorithms/algorithms_basics.htm)\n",
    "\n",
    "## Analysis of Algorithms:\n",
    "Highly Recommended Read (Have a profound look at each topic): [Analysis of Algorithms](https://www.geeksforgeeks.org/fundamentals-of-algorithms/#AnalysisofAlgorithms)\n",
    "\n",
    "Efficiency of an algorithm can be analyzed at two different stages:\n",
    "\n",
    ">**A Priori Analysis: ** This is a theoretical analysis of an algorithm i.e. a pre-implementation analysis. Efficiency of an algorithm is measured by performing Asyptotic analysis whereby assuming that all other factors, for example, processor speed, are constant and have no effect on the implementation.\n",
    "\n",
    ">**A Posterior Analysis: ** This is an empirical analysis of an algorithm i.e. a post-implementation analysis. The selected algorithm is implemented using programming language. This is then executed on target computer machine. In this analysis, actual statistics like running time and space required, are collected.\n",
    "\n",
    "\n",
    "### Algorithm Complexity:\n",
    "Recommended Read: [Algorithmic Complexity](https://www.cs.cmu.edu/~adamchik/15-121/lectures/Algorithmic%20Complexity/complexity.html) <br>\n",
    "Time Complexity Analysis Concise Video Series: [Time Complexity](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI9HK8YPVBjElbLbI3ufctn)\n",
    "\n",
    "\n",
    "Some algorithms are more efficient than others. We would prefer to chose an efficient algorithm, so it would be nice to have metrics for comparing algorithm efficiency.\n",
    "\n",
    "The complexity of an algorithm is a function describing the efficiency of the algorithm in terms of the amount of data (inputs) the algorithm must process. Usually there are natural units for the domain and range of this function. There are two main complexity measures of the efficiency of an algorithm:\n",
    "\n",
    ">**Time complexity** is a function describing the amount of time an algorithm takes in terms of the amount of input to the algorithm. \"Time\" can mean the number of memory accesses performed, the number of comparisons between integers, the number of times some inner loop is executed, or some other natural unit related to the amount of real time the algorithm will take. We try to keep this idea of time separate from \"wall clock\" time, since many factors unrelated to the algorithm itself can affect the real time (like the language used, type of computing hardware, proficiency of the programmer, optimization in the compiler, etc.). It turns out that, if we chose the units wisely, all of the other stuff doesn't matter and we can get an independent measure of the efficiency of the algorithm.\n",
    "\n",
    ">**Space complexity** is a function describing the amount of memory (space) an algorithm takes in terms of the amount of input to the algorithm. We often speak of \"extra\" memory needed, not counting the memory needed to store the input itself. Again, we use natural (but fixed-length) units to measure this. We can use bytes, but it's easier to use, say, number of integers used, number of fixed-sized structures, etc. In the end, the function we come up with will be independent of the actual number of bytes needed to represent the unit. Space complexity is sometimes ignored because the space used is minimal and/or obvious, but sometimes it becomes as important an issue as time.\n",
    "For example, we might say \"this algorithm takes n2 time,\" where n is the number of items in the input. Or we might say \"this algorithm takes constant extra space,\" because the amount of extra memory needed doesn't vary with the number of items processed.\n",
    "\n",
    "For both time and space, we are interested in the asymptotic complexity of the algorithm: When n (the number of items of input) goes to infinity, what happens to the performance of the algorithm?\n",
    "\n",
    "The term analysis of algorithms is used to describe approaches to the study of the performance of algorithms. In this course we will perform the following types of analysis:\n",
    "- the **worst-case runtime complexity** of the algorithm is the function defined by the maximum number of steps taken on any instance of size a.\n",
    "- the **best-case runtime complexity** of the algorithm is the function defined by the minimum number of steps taken on any instance of size a.\n",
    "- the **average case runtime complexity** of the algorithm is the function defined by an average number of steps taken on any instance of size a.\n",
    "- the **amortized runtime complexity** of the algorithm is the function defined by a sequence of operations applied to the input of size a and averaged over time.\n",
    "\n",
    "**Asymptotic Analysis:**\n",
    "\n",
    "It is the most effective way of doint a priori analysis. Notations used in asymptotic analysis are refered to as asymptotic notations. Asymptotic Notations could be regarded as a language that allow us to analyze an algorithm’s running time by identifying its behavior as the input size for the algorithm increases. This is also known as an algorithm’s growth rate. Does the algorithm suddenly become incredibly slow when the input size grows? Does it mostly maintain its quick run time as the input size increases? Asymptotic Notation gives us the ability to answer these questions. <br>\n",
    "Recommended  Read: [Asymptotic Notation](https://learnxinyminutes.com/docs/asymptotic-notation/)<br>\n",
    "Alternative Read: [Asymptotic Notation](https://www.geeksforgeeks.org/analysis-of-algorithms-set-3asymptotic-notations/)\n",
    "\n",
    "Ques: Why do we use Big-O to represent the complexity in most cases and not Big-Omega or Theta? <br>\n",
    "Ans: Because in domain of computer science we take a pessimistic view, as we cann't assume anything about the input therefore  at all times we are concerned with the worst case complexity of our algorithm, i.e., we want to find out the upper bound for our algorithm which communicates the maximum/utmost rate of growth of our algorithm's runtime/space-consumption in terms of growth of the input size.\n",
    "\n",
    "Note: **Asymptotic runtimes are functions of the input size**, i.e., they communicate how the runtime(time or space) would scale as the input size grows larger and larger. Asymptotic runtime is a handy tool for comparing/analyzing algorithms before implementation, however, they aren't exact rather provide an approximate idea of the runtimes. Therefore, for exact runtime of the algorithm over a given architecture is done using the Posterior analysis.\n",
    "\n",
    "**Growth Rate (w.r.t. input size) of various function**\n",
    "\n",
    "![](./Images-Algorithms/GrowthRate.png \"Growth rate of different functions\")\n",
    "\n",
    "### Complexity (Big-O) for various Data Structures and Algorithms\n",
    "\n",
    "**Goodness Scale: **![](./Images-Algorithms/GoodnessScale.png \"Goodness Scale\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-DataStructures.png \"Big-O complexity for Data Structures\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Searching.png \"Big-O complexity for Searching\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Sorting.png \"Big-O complexity for Sorting\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Heaps.png \"Big-O complexity for Heaps\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Graphs.png \"Big-O complexity for Graphs\")\n",
    "\n",
    "\n",
    "\n",
    "Responsive Cheat Sheet: [Big O and Growth Rate Cheat Sheets](http://cooervo.github.io/Algorithms-DataStructures-BigONotation/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Algorithm Design Paradigms\n",
    "\n",
    "### Introduction\n",
    "\n",
    ">**Algorithm Design Paradigms:** General approaches to the construction of efficient solutions to problems.\n",
    "\n",
    "Such methods are of interest because:\n",
    "\n",
    "- They provide templates suited to solving a broad range of diverse problems.\n",
    "- They can be translated into common control and data structures provided by most high-level languages.\n",
    "- The temporal and spatial requirements of the algorithms which result can be precisely analyzed.\n",
    "\n",
    "Although more than one technique may be applicable to a specific problem, it is often the case that an algorithm constructed by one approach is clearly superior to equivalent solutions built using alternative techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Brute Force\n",
    "\n",
    ">Brute force is a straightforward approach to solve a problem based on the problem’s statement and definitions of the concepts involved. It is considered as one of the easiest approach to apply and is useful for solving small – size instances of a problem.\n",
    "\n",
    "Some examples of brute force algorithms are: \n",
    "- Computing an (a > 0, n a nonnegative integer) by multiplying a x a x… x a\n",
    "- Computing n!\n",
    "- Selection sort \n",
    "- Bubble sort\n",
    "- Sequential search \n",
    "- Exhaustive search: Traveling Salesman Problem, Knapsack problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Greedy Algorithms \"take what you can get now\" strategy\n",
    "\n",
    ">The solution is constructed through a sequence of steps, each expanding a partially constructed solution obtained so far. At each step the choice must be locally optimal – this is the central point of this technique. Greedy techniques are mainly used to solve optimization problems. They do not always give the best solution.\n",
    " \n",
    "Example:\n",
    "\n",
    "Consider the knapsack problem with a knapsack of capacity 10 and 4 items given by the < weight:value > pairs: < 5:6 >, < 4:3 >, < 3: 5 >, < 3: 4 >. The greedy algorithm will choose item 1 < 5:6 > and then item 3 < 3:5 >, as it tries to get local optimals, resulting in total value 11(which is not optimal globally), while the optimal solution is to choose items 2, 3, and 4 thus obtaining total value 12.\n",
    "\n",
    "Note: It has been proven that greedy algorithms for the minimal spanning tree, the shortest paths, and Huffman codes  always give the optimal solution.\n",
    "\n",
    "More Examples: \n",
    "\n",
    "- Minimal spanning tree\n",
    "- Shortest distance in graphs\n",
    "- Greedy algorithm for the Knapsack problem\n",
    "- The coin exchange problem\n",
    "- Huffman trees for optimal encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Divide-and-Conquer, Decrease-and-Conquer\n",
    "These are methods of designing algorithms that (informally) proceed as follows:\n",
    "\n",
    ">Given an instance of the problem to be solved, split this into several smaller sub-instances (of the same problem), independently solve each of the sub-instances and then combine the sub-instance solutions so as to yield a solution for the original instance.\n",
    "\n",
    "Note: With the divide-and-conquer method the size of the problem instance is reduced by a factor (e.g. half the input size), while with the decrease-and-conquer method the size is reduced by a constant.\n",
    "\n",
    "Examples of divide-and-conquer algorithms:\n",
    "\n",
    "- Computing an (a > 0, n a nonnegative integer) by recursion\n",
    "- Binary search in a sorted array (recursion)\n",
    "- Mergesort algorithm, Quicksort algorithm  (recursion)\n",
    "- The algorithm for solving the fake coin problem (recursion)\n",
    "\n",
    "Examples of decrease-and-conquer algorithms:\n",
    "\n",
    "- Insertion sort\n",
    "- Topological sorting\n",
    "- Binary Tree traversals: inorder, preorder and postorder (recursion)\n",
    "- Computing the length of the longest path in a binary tree (recursion)\n",
    "- Computing Fibonacci numbers (recursion)\n",
    "- Reversing a queue (recursion)\n",
    "- Warshall’s algorithm (recursion)\n",
    "\n",
    "**The issues here are two:**\n",
    "\n",
    "- How to solve the sub-instance?\n",
    "- How to combine the obtained solutions?\n",
    "\n",
    "**Addressing issues:**\n",
    "- The answer to the second question depends on the nature of the problem.\n",
    "- In most cases the answer to the first question is: using the same method(break it down further). <br> Here another very important issue arises: when to stop decreasing the problem instance, i.e. what is the minimal instance of the given problem and how to solve it?\n",
    "\n",
    "When we use recursion, the solution of the minimal instance is called “terminating condition”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dynamic Programming\n",
    "One disadvantage of using Divide-and-Conquer is that the process of recursively solving separate sub-instances can result in the same computations being performed repeatedly since identical sub-instances may arise.\n",
    "\n",
    ">The idea behind dynamic programming is to avoid this pathology by obviating the requirement to calculate the same quantity twice. The method usually accomplishes this by maintaining a table of sub-instance results i.e. memoizing the resultls of the sub-problems.\n",
    "\n",
    "Dynamic Programming is a Bottom-Up Technique in which the smallest sub-instances are explicitly solved first and the results of these used to construct solutions to progressively larger sub-instances.\n",
    "\n",
    "In contrast, Divide-and-Conquer is a Top-Down Technique which logically progresses from the initial instance down to the smallest sub-instance via intermediate sub-instances game.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Fibonacci numbers computed by iteration.\n",
    "- Warshall’s algorithm implemented by iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Backtracking and branch-and-bound: generate and test methods\n",
    "The method is used for state-space search problems. State-space search problems are problems, where the problem representation consists of:\n",
    "- initial state\n",
    "- goal state(s)\n",
    "- a set of intermediate states\n",
    "- a set of operators that transform one state into another. Each operator has preconditions and postconditions.\n",
    "- a cost function – evaluates the cost of the operations (optional)\n",
    "- a utility function – evaluates how close is a given state to the goal state (optional)\n",
    "\n",
    "\n",
    ">The solving process solution is based on the construction of a **state-space tree**, whose nodes represent states, the root represents the initial state, and one or more leaves are goal states. Each edge is labeled with some operator. \n",
    "\n",
    ">If a node *b* is obtained from a node *a* as a result of applying the operator *O*, then *b* is a child of *a* and the edge from *a* to *b* is labeled with *O*.<br>\n",
    "The solution is obtained by searching the tree until a goal state is found.\n",
    "\n",
    "\n",
    "**Backtracking uses depth-first search** usually without cost function. <br>The main algorithm is as follows:\n",
    "\n",
    ">1. Store the initial state in a stack\n",
    ">2. While the stack is not empty, do:\n",
    "\n",
    "    >>1. Read a node from the stack.\n",
    "    >>2. While there are available operators do:\n",
    "    \n",
    "        >>>1. Apply an operator to generate a child\n",
    "        >>>2. If the child is a goal state – stop\n",
    "        >>>3. If it is a new state, push the child into the stack\n",
    "        \n",
    "The utility function is used to tell how close is a given state to the goal state and whether a given state may be considered a goal state.<br>\n",
    "If no children can be generated from a given node, then we **backtrack** – read the next node from the stack.\n",
    "\n",
    "Example: The following problems can be solved using state-space search techniques:\n",
    "1. A farmer has to move a goat, a cabbage and a wolf from one side of a river to the other side using a small boat. The boat can carry only the farmer and one more object (either the goat, or the cabbage, or the wolf). If the farmer leaves the goat with the wolf alone, the wolf would kill the goat. If the goat is alone with the cabbage, it will eat the cabbage. How can the farmer move all his property safely to the other side of the river?\"<br> <br>\n",
    "\n",
    "2. You are given two jugs, a 4-gallon one and a 3-gallon one. Neither has any measuring markers on it. There is a tap that can be used to fill the jugs with water. How can you get exactly 2 gallons of water into the 4-gallon jug?\n",
    "\n",
    "We have to decide:\n",
    "\n",
    "1. representation of the problem state, initial and final states\n",
    "2. representation of the actions available in the problem, in terms of how they change the problem state.\n",
    "\n",
    "**Branch-and-bound:**\n",
    ">Branch and bound is used when we can evaluate each node using the cost and utility functions. At each step we choose the best node to proceed further. Branch-and bound algorithms are implemented using a priority queue. The state-space tree is built in a breadth-first manner.\n",
    "\n",
    "Example: The 8-puzzle problem. The cost function is the number of moves. The utility function evaluates how close is a given state of the puzzle to the goal state, example counting how many tiles are not in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Transform-and-Conquer\n",
    "These methods work as two-stage procedures. First, the problem is modified to be more amenable to solution. In the second stage the problem is solved.\n",
    "\n",
    "Types of problem modifications:\n",
    "\n",
    "- **Problem simplification** e.g. presorting <br>\n",
    "  Example: consider the problem of finding the two closest numbers in an array of numbers.\n",
    "      Brute force solution: O(n2)\n",
    "      Transform and conquer solution: O(nlogn)\n",
    "           Presort the array – O(nlogn)\n",
    "           Scan the array comparing the differences - O(n)\n",
    "- **Change in the representation** <br>\n",
    "    Example: AVL trees guarantee O(nlogn) search time\n",
    "- **Problem reduction** <br>\n",
    "    Example: least common multiple\n",
    "        lcm(m,n) = (m*n)/ gcd(m,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Genetic Algorithms\n",
    "Genetic algorithms (GAs) are used mainly for optimization problems for which the exact algorithms are of very low efficiency.\n",
    "\n",
    "GAs search for good solutions to a problem from among a (large) number of possible solutions. The current set of possible solutions is used to generate a new set of possible solution.\n",
    "\n",
    ">They start with an initial set of possible solutions, and at each step they do the following:\n",
    "\n",
    ">1. evaluate the current set of solutions (current generation)\n",
    ">2. choose the best of them to serve as “parents” for the new generation, and construct the new generation.\n",
    "\n",
    ">The loop runs until a specified condition becomes true, e.g. a solution is found that satisfies the criteria for a “good” solution, or the number of iterations exceeds a given value, or no improvement ahs been recorded when evaluation the solutions.\n",
    "\n",
    "Key issues here are:\n",
    "\n",
    ">1. How large to be the **size of a population** so that there is sufficient diversity? Usually the size is determined through trial-and-error experiments.<br><br>\n",
    "\n",
    ">2. How to represent the solutions so that the representations can be manipulated to obtain a new solution? One approach is to represent the solutions as strings of characters (could be binary strings) and to use various types of “crossover” (explained below) to obtain a new set of solutions. The strings are usually called **“chromosomes”**.<br><br>\n",
    "\n",
    ">3. how to evaluate a solution?. The function used to evaluate a solution is called **“fitness function”** and it depends on the nature of the problem.<br><br>\n",
    "\n",
    ">4. How to manipulate the representations in order to construct a new solution? The method that is characteristic of GAs is to combine two or more representations by taking substrings of each of them to construct a new solution. This operation is called **“crossover”**.<br><br>\n",
    "\n",
    ">5. How to choose the individual solutions that will serve as parents for the new generation? The process of choosing parents is called **“selection”**. Various methods have been experimented here. It seems that the choice is dependent on the nature of the problem and the chosen representation. One method is to choose parents with a probability proportional to their fitness. This method is called “roulette wheel selection”.<br><br>\n",
    "\n",
    ">6. How to avoid convergence to a set of equal solutions? The approach here is to change randomly the representation of a solution. If the representation is a bit string we can flip bits. This operation is called **“mutation”**.<br><br>\n",
    "\n",
    "Using the terminology above, we can outline the algorithms to obtain one generation:\n",
    "\n",
    "- compute the fitness of each chromosome\n",
    "- select parents based on the fitness value and a selection strategy\n",
    "- perform crossover to obtain new chromosomes\n",
    "- perform mutation on the new chromosomes (with fixed or random probability)\n",
    "\n",
    "Examples: \n",
    "\n",
    "- The knapsack problem solved with GAs\n",
    "- The traveling salesman problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Usually a given problem can be solved using various approaches however it is not wise to settle for the first that comes to mind. More often than not, some approaches result in much more efficient solutions than others.    Consider again the Fibonacci numbers computed recursively using the decrease-and-conquer approach, and computed by iterations using dynamic programming. In the first case the complexity is O($2^{n}$), while in the second case the complexity is O(n). \n",
    "On the other hand, consider sorting based on decrease-and-conquer (insertion sort) and brute force sorting. For almost sorted files insertion sort will give almost linear complexity, while brute force sorting algorithms have quadratic complexity.\n",
    "\n",
    "The basic question here is: How to choose the approach? <br>\n",
    "First, by understanding the problem and <br>\n",
    "Second, by knowing various problems and how they are solved using different approaches. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P vs NP\n",
    "Highly Recommended Watch: [P vs NP](https://www.youtube.com/watch?v=YX40hbAHx3s)\n",
    "\n",
    "We have seen efficient algorithms to solve complex problems, like shortest path, Euler graph, minimum spanning tree, etc. Those were all success stories of algorithm designers. Now is the time to ponder upon their failures.\n",
    "\n",
    "![](./Images-Algorithms/P VS NP.png \"P vs NP\")\n",
    "\n",
    "**Can all computational problems be solved by a computer?** <br>\n",
    "There are computational problems that can not be solved by algorithms even with unlimited time. For example Turing Halting problem (Given a program and an input, whether the program will eventually halt when run with that input, or will run forever). Alan Turing proved that general algorithm to solve the halting problem for all possible program-input pairs cannot exist.\n",
    "\n",
    "Note: Turing Machine is a mathematical model of a hypothetical computing machine which can use a predefined set of rules to determine a result from a set of input variables.\n",
    "\n",
    "**Status of NP Complete problems** is another failure story, NP complete problems are problems whose status is unknown. No polynomial time algorithm has yet been discovered for any NP complete problem, nor has anybody yet been able to prove that no polynomial-time algorithm exist for any of them. The interesting part is, if any one of the NP complete problems can be solved in polynomial time, then all of them can be solved (cuz they are reducable, in some way, to one another).\n",
    "\n",
    "### What are NP, P, NP-complete and NP-Hard problems?\n",
    "\n",
    ">**P** is set of problems that can be solved by a deterministic Turing machine in Polynomial time.\n",
    "\n",
    ">**NP** is set of decision problems that can be solved by a Non-deterministic Turing Machine in Polynomial time. P is subset of NP (any problem that can be solved by deterministic machine in polynomial time can also be solved by non-deterministic machine in polynomial time).\n",
    "Informally, NP is set of decision problems which can be solved by a polynomial time via a “Lucky Algorithm”, a magical algorithm that always makes a right guess among the given set of choices \n",
    "\n",
    ">**NP-complete** problems are the hardest problems in NP set.  A decision problem L is NP-complete if:\n",
    "1. L is in NP (Any given solution for NP-complete problems can be verified quickly, but there is no efficient known solution).\n",
    "2. Every problem in NP is reducible to L in polynomial time (Reduction is defined below).\n",
    "\n",
    ">A problem is **NP-Hard** if it follows property 2 mentioned above, doesn’t need to follow property 1. Therefore, NP-Complete set is also a subset of NP-Hard set.\n",
    "\n",
    "\n",
    "**Decision vs Optimization Problems**\n",
    "\n",
    "NP-completeness applies to the realm of decision problems. It was set up this way because it’s easier to compare the difficulty of decision problems than that of optimization problems. In reality, though, being able to solve a decision problem in polynomial time will often permit us to solve the corresponding optimization problem in polynomial time (using a polynomial number of calls to the decision problem). So, discussing the difficulty of decision problems is often really equivalent to discussing the difficulty of optimization problems. \n",
    "\n",
    "For example, consider the vertex cover problem (Given a graph, find out the minimum sized vertex set that covers all edges). It is an optimization problem. Corresponding decision problem is, given undirected graph G and k, is there a vertex cover of size k?\n",
    "\n",
    "**What is Reduction?**\n",
    "\n",
    ">Let L1 and L2 be two decision problems. Suppose algorithm A2 solves L2. That is, if y is an input for L2 then algorithm A2 will answer Yes or No depending upon whether y belongs to L2 or not.\n",
    "The idea is to find a transformation from L1 to L2 so that the algorithm A2 can be part of an algorithm A1 to solve L1.\n",
    "\n",
    "Learning reduction in general is very important. For example, if we have library functions to solve certain problem and if we can reduce a new problem to one of the solved problems, we save a lot of time. Consider the example of a problem where we have to find minimum product path in a given directed graph where product of path is multiplication of weights of edges along the path. If we have code for Dijkstra’s algorithm to find shortest path, we can take log of all weights and use Dijkstra’s algorithm to find the minimum product path rather than writing a fresh code for this new problem.\n",
    "\n",
    "**How to prove that a given problem is NP complete?**\n",
    "\n",
    "From the definition of NP-complete, it appears impossible to prove that a problem L is NP-Complete.  By definition, it requires us to that show every problem in NP is polynomial time reducible to L. Fortunately, there is an alternate way to prove it. The idea is to take a known NP-Complete problem and reduce it to L. If polynomial time reduction is possible, we can prove that L is NP-Complete by transitivity of reduction (If a NP-Complete problem is reducible to L in polynomial time, then all problems are reducible to L in polynomial time).\n",
    "\n",
    "**What was the first problem proved as NP-Complete?**\n",
    "\n",
    "There must be some first NP-Complete problem proved by definition of NP-Complete problems.  SAT (Boolean satisfiability problem) is the first NP-Complete problem proved.\n",
    "\n",
    "It is always useful to know about NP-Completeness even for engineers. Suppose you are asked to write an efficient algorithm to solve an extremely important problem for your company. After a lot of thinking, you can only come up exponential time approach which is impractical. If you don’t know about NP-Completeness, you can only say that I could not come with an efficient algorithm. If you know about NP-Completeness and prove that the problem as NP-complete, you can proudly say that the polynomial time solution is unlikely to exist. If there is a polynomial time solution possible, then that solution solves a big problem of computer science many scientists have been trying for years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Algorithms Implementation\n",
    "For Data Structures and Algorithms visualization, explanation and psuedocode refer to: [VisuAlgo](https://visualgo.net/en)\n",
    "\n",
    "## Search Algorithms\n",
    "More Search Algorithms: [Search Algorithms](https://www.geeksforgeeks.org/searching-algorithms/)\n",
    "\n",
    "### Sequential/Linear Search [Generic]\n",
    "\n",
    "![](./Images-Algorithms/SequentialUnordered.png \"Sequential Search Analysis for Unordered list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def seq_search(arr,ele):\n",
    "    \"\"\"\n",
    "    General Sequential Search. Works on Unordered lists.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start at position 0\n",
    "    pos = 0\n",
    "    # Target becomes true if ele is in the list\n",
    "    found = False\n",
    "    \n",
    "    # go until end of list\n",
    "    while pos < len(arr) and not found:\n",
    "        \n",
    "        # If match\n",
    "        if arr[pos] == ele:\n",
    "            found = True\n",
    "            \n",
    "        # Else move one down\n",
    "        else:\n",
    "            pos  = pos+1\n",
    "    \n",
    "    return found\n",
    "\n",
    "def exec():\n",
    "    arr = [1,9,2,8,3,4,7,5,6]\n",
    "\n",
    "    print(seq_search(arr,1))\n",
    "    print(seq_search(arr,10))\n",
    "\n",
    "exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential/Linear Search [Ordered]\n",
    "Note: Having an ordered list would improve the runtime complexity of the sequential search.<br> [We can further take the complexity to log n by using Binary Search (implemented next)]\n",
    "\n",
    "![](./Images-Algorithms/SequentialOrdered.png \"Sequential Search Analysis for Unordered list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def ordered_seq_search(arr,ele):\n",
    "    \"\"\"\n",
    "    Sequential search for an Ordered list\n",
    "    \"\"\"\n",
    "    # Start at position 0\n",
    "    pos = 0\n",
    "    \n",
    "    # Target becomes true if ele is in the list\n",
    "    found = False\n",
    "    \n",
    "    # Stop marker\n",
    "    stopped = False\n",
    "    \n",
    "    # go until end of list\n",
    "    while pos < len(arr) and not found and not stopped:\n",
    "        \n",
    "        # If match\n",
    "        if arr[pos] == ele:\n",
    "            found = True\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if arr[pos] > ele:\n",
    "                stopped = True\n",
    "                # Check if element is greater\n",
    "\n",
    "            # Otherwise move on\n",
    "            else:\n",
    "                pos  = pos+1\n",
    "    \n",
    "    return found\n",
    "\n",
    "def exec():\n",
    "    arr = [1,9,2,8,3,4,7,5,6]\n",
    "    arr.sort() \n",
    "    print(ordered_seq_search(arr,3))\n",
    "    print(ordered_seq_search(arr,1.5))\n",
    "    \n",
    "exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Binary Search:\n",
    "Note: Binary Search required the list to be ordered and uses Divide and Conquer design paradigm.\n",
    "\n",
    "![](./Images-Algorithms/BinarySearchAnalysis.png \"Sequential Search Analysis for Unordered list\")\n",
    "\n",
    "**Iterative Binary Search:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def binary_search(arr,ele):\n",
    "    \n",
    "    # First and last index values\n",
    "    first = 0\n",
    "    last = len(arr) - 1\n",
    "    \n",
    "    found = False\n",
    "    \n",
    "    \n",
    "    while first <= last and not found:\n",
    "        \n",
    "        mid = (first+last)//2 \n",
    "        \n",
    "        # Match found\n",
    "        if arr[mid] == ele:\n",
    "            found = True\n",
    "        \n",
    "        # Set new midpoints up or down depending on comparison\n",
    "        else:\n",
    "            # Set down\n",
    "            if ele < arr[mid]:\n",
    "                last = mid -1\n",
    "            # Set up \n",
    "            else:\n",
    "                first = mid + 1\n",
    "                \n",
    "    return found\n",
    "\n",
    "def exec():\n",
    "    # list must already be sorted!\n",
    "    arr = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "    print(binary_search(arr,4))\n",
    "    print(binary_search(arr,2.2))\n",
    "    \n",
    "exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive Binary Search:** [Elegant design, indeed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def rec_bin_search(arr,ele):\n",
    "    \n",
    "    # Base Case!\n",
    "    if len(arr) == 0:\n",
    "        return False\n",
    "    \n",
    "    # Recursive Case\n",
    "    else:\n",
    "        \n",
    "        mid = len(arr)//2\n",
    "        \n",
    "        # If match found\n",
    "        if arr[mid]==ele:\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Call again on second half\n",
    "            if ele<arr[mid]:\n",
    "                return rec_bin_search(arr[:mid],ele)\n",
    "            \n",
    "            # Or call on first half\n",
    "            else:\n",
    "                return rec_bin_search(arr[mid+1:],ele)\n",
    "            \n",
    "def exec():\n",
    "    # list must already be sorted!\n",
    "    arr = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "    print(rec_bin_search(arr,4))\n",
    "    print(rec_bin_search(arr,2.2))\n",
    "    \n",
    "exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing\n",
    "Recommended Read: MIT/IntroductionToAlgorithms/Lecture Notes/Unit3-Hashing<br>\n",
    "Recommended Read: [Hashing](https://www.geeksforgeeks.org/hashing-set-1-introduction/)<br>\n",
    "Recommended Watch:PythonForDataStructuresAlgorithmsandInterviews/17SearchingandSorting/Hashing\n",
    "\n",
    "We have seen  how to improve search by knowing about structures beforehand. From linear to binary search we improved the complexity from linear to logarithmic. But can we get to a constant search time?\n",
    "\n",
    ">We can build a data structure that can be searched in O(1) time. This concept is referred to as hashing and the data structure is referred to as hashing data structure. Hashing is an improvement over the Direct Access Table where time complexity is constant but the space complexity is huge (as can be extrapolated from the recommended read above). So, to get this space complexity down we use the hashing mechanism. The idea is to use hash function that converts a key to a smaller number, i.e. from a larger domain of keys we move towards a smaller domain, and uses the small number as index in a table called hash table.\n",
    "\n",
    "Note: Hashing is a part of Data Structure but it originates from the requirement of searching in constant time (that's why we are studying it under algorithms notebook).\n",
    "\n",
    "**Hash Functions:** A hash function is any function that can be used to map data of arbitrary size to data of a fixed size. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes. Hash functions provides the mapping between the item and the slots in the hash table.\n",
    "\n",
    "A hash function that maps each item into a unique slot is referred to as a perfect hash function (zero collision).\n",
    "\n",
    "Properties of Hash Function: \n",
    "- One way; can not be reversed\n",
    "- Output does not reveal information on input\n",
    "- Hard to find collisions(different messages with same hash)\n",
    "\n",
    "Following are few Hash Function: [Refer to recommended watch for details] \n",
    "- Remainder Method (key % hash_table_size gives the slot number(index) for that key in that hash table)<br>\n",
    "  Example for string keys: <br>\n",
    "  Each character in the string is converted into it's corresponding int value, using the ord(char) which provides unicode val for one-char strings in python, and all character values are summed to get a final key value which is then divided by the hash_table_size to get the slot number.<br><br>\n",
    "- Folding Method\n",
    "- Mid Square Method \n",
    "\n",
    "\n",
    "**Collision:** Since a hash function gets us a small number for a big key, there is possibility that two keys result in same value. The situation where a newly inserted key maps to an already occupied slot in hash table is called collision.\n",
    "\n",
    "Rehashing: The general name for the process of looking for another slot after a collision is rehashing.\n",
    "\n",
    "**Collision Handling/Resolution Methods:** [Go through Unit-3 in Introduction to Algorithms by MIT]\n",
    "- [Chaining](https://www.geeksforgeeks.org/hashing-set-2-separate-chaining/)\n",
    "- [Open Addressing](https://www.geeksforgeeks.org/hashing-set-3-open-addressing/)\n",
    "\n",
    "### Implementation of a Hash Table\n",
    "\n",
    "Here, we will be implementing our own Hash Table to complete our understanding of Hash Tables and Hash Functions! Keep in mind that Python already has a built-in dictionary object that serves as a Hash Table, you would never actually need to implement your own hash table in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable(object):\n",
    "    \"Blueprint to create Hash Table using lists as the base.\"\n",
    "    \n",
    "    def __init__(self,size):\n",
    "        \n",
    "        # Set up size and slots and data\n",
    "        self.size = size\n",
    "        self.slots = [None] * self.size \n",
    "        self.data = [None] * self.size    \n",
    "        \n",
    "    def put(self,key,data):\n",
    "        #Note, we'll only use integer keys for ease of use with the Hash Function\n",
    "        \n",
    "        # Get the hash value\n",
    "        hashvalue = self.hashfunction(key,len(self.slots))\n",
    "\n",
    "        # If Slot is Empty\n",
    "        if self.slots[hashvalue] == None:\n",
    "            self.slots[hashvalue] = key\n",
    "            self.data[hashvalue] = data\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # If key already exists, replace old value\n",
    "            if self.slots[hashvalue] == key:\n",
    "                self.data[hashvalue] = data  \n",
    "            \n",
    "            # Otherwise, the slot is pre-occupied find the next available slot using open addressing with linear probing\n",
    "            else:\n",
    "                \n",
    "                nextslot = self.rehash(hashvalue,len(self.slots))\n",
    "                \n",
    "                # Get to the next slot\n",
    "                while self.slots[nextslot] != None and self.slots[nextslot] != key:\n",
    "                    nextslot = self.rehash(nextslot,len(self.slots))\n",
    "                \n",
    "                # Set new key, if NONE\n",
    "                if self.slots[nextslot] == None:\n",
    "                    self.slots[nextslot]=key\n",
    "                    self.data[nextslot]=data\n",
    "                    \n",
    "                # Otherwise replace old value\n",
    "                else:\n",
    "                    self.data[nextslot] = data \n",
    "\n",
    "    def hashfunction(self,key,size):\n",
    "        # Remainder Method\n",
    "        return key%size\n",
    "\n",
    "    def rehash(self,oldhash,size):\n",
    "        # For finding next possible positions with linear probing\n",
    "        return (oldhash+1)%size\n",
    "    \n",
    "    \n",
    "    def get(self,key):\n",
    "        \n",
    "        # Getting items given a key\n",
    "        \n",
    "        # Set up variables for our search\n",
    "        startslot = self.hashfunction(key,len(self.slots))\n",
    "        data = None\n",
    "        stop = False\n",
    "        found = False\n",
    "        position = startslot\n",
    "        \n",
    "        # Until we discern that its not empty or found (and haven't stopped yet)\n",
    "        while self.slots[position] != None and not found and not stop:\n",
    "            \n",
    "            if self.slots[position] == key:\n",
    "                found = True\n",
    "                data = self.data[position]\n",
    "                \n",
    "            else:\n",
    "                position=self.rehash(position,len(self.slots))\n",
    "                if position == startslot:\n",
    "                    \n",
    "                    stop = True\n",
    "        return data\n",
    "\n",
    "    # Special Methods for use with Python indexing\n",
    "    def __getitem__(self,key):\n",
    "        return self.get(key)\n",
    "\n",
    "    def __setitem__(self,key,data):\n",
    "        self.put(key,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Savage Dominating None\n"
     ]
    }
   ],
   "source": [
    "def exec():\n",
    "    h = HashTable(5)\n",
    "    h[200] = \"Savage\"\n",
    "    h[27] = \"Dominating\"\n",
    "    print(h[200], h[27], h[0])\n",
    "exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Algorithms\n",
    "More Sorting Algorithms: [Sorting Algorithms](https://www.cdn.geeksforgeeks.org/sorting-algorithms/) <br>\n",
    "Visualize them to better understand: [Visual Algo](http://visualgo.net/sorting.html)\n",
    "\n",
    "\n",
    "### Bubble Sort\n",
    "**Overview:** The bubble sort makes multiple passes through a list. It compares adjacent items and exchanges those that are out of order. Each pass through the list places the next largest value in its proper place. In essence, each item “bubbles” up to the location where it belongs.\n",
    "\n",
    "![](./Images-Algorithms/BubbleSortAnalysis.png \"Bubble Sort Analysis\")\n",
    "\n",
    "**psuedocode:**\n",
    "```\n",
    "do\n",
    "  swapped = false \n",
    "  \n",
    "  for i = 1 to indexOfLastUnsortedElement-1\n",
    "    if leftElement > rightElement\n",
    "      swap(leftElement, rightElement)\n",
    "      swapped = true\n",
    "      \n",
    "while swapped\n",
    "```\n",
    "\n",
    "**Implementation of Bubble Sort: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted array is:\n",
      "11 12 22 25 34 64 90 "
     ]
    }
   ],
   "source": [
    "def bubbleSort(arr):\n",
    "    n = len(arr)\n",
    " \n",
    "    #Iterate over the array len(arr) number of time or uptil array gets sorted\n",
    "    for i in range(n):\n",
    " \n",
    "        swap = False\n",
    "        # Last i elements are already in place\n",
    "        for j in range(0, n-i-1):\n",
    " \n",
    "            # traverse the array from 0 to n-i-1\n",
    "            # Swap if the element found is greater\n",
    "            # than the next element\n",
    "            if arr[j] > arr[j+1] :\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "                swap = True\n",
    "        \n",
    "        if not swap:  #No swaps took place in the last iteration >> list sorted, hence break \n",
    "            break \n",
    "                 \n",
    "\n",
    "def exec():\n",
    "    arr = [64, 34, 25, 12, 22, 11, 90]\n",
    "\n",
    "    bubbleSort(arr)\n",
    "\n",
    "    print (\"Sorted array is:\")\n",
    "    for i in range(len(arr)):\n",
    "        print(arr[i], end = \" \")\n",
    "\n",
    "exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Sort\n",
    "**Overview:** The selection sort algorithm sorts an array by repeatedly finding the minimum element (considering ascending order) from unsorted part and putting it at the beginning. The algorithm maintains two subarrays in a given array.\n",
    "\n",
    "1. The subarray which is already sorted.\n",
    "2. Remaining subarray which is unsorted.\n",
    "\n",
    "In every iteration of selection sort, the minimum element (considering ascending order) from the unsorted subarray is picked and moved to the sorted subarray.\n",
    "\n",
    "**Analysis:**\n",
    "- Time Complexity: O($n^{2}$)\n",
    "- Space Complexity [Auxilary Space]: O(1)\n",
    "\n",
    "**psuedocode:**<br>\n",
    "```\n",
    "repeat (numOfElements - 1) times\n",
    "\n",
    "      set the first unsorted element as the minimum\n",
    "      for each of the unsorted elements\n",
    "\n",
    "            if element < currentMinimum\n",
    "              set element as new minimum\n",
    "\n",
    "      swap minimum with first unsorted position\n",
    "  ```\n",
    "\n",
    "**Implementation of Selection Sort:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted array:  11 12 22 25 64 "
     ]
    }
   ],
   "source": [
    "def selection_sort(A):\n",
    "    \n",
    "    # Traverse through all array elements\n",
    "    for i in range(len(A)):\n",
    "\n",
    "        # Find the minimum element in remaining unsorted array\n",
    "        min_idx = i\n",
    "        for j in range(i+1, len(A)):\n",
    "            if A[min_idx] > A[j]:\n",
    "                min_idx = j\n",
    "\n",
    "        # Swap the found minimum element with the first element        \n",
    "        A[i], A[min_idx] = A[min_idx], A[i]\n",
    "\n",
    "\n",
    "def exec():\n",
    "    arr = [64, 25, 12, 22, 11]\n",
    "    selection_sort(arr)\n",
    "    print (\"Sorted array: \", end = \" \")\n",
    "    for i in range(len(arr)):\n",
    "        print(arr[i], end = \" \")\n",
    "exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion Sort\n",
    "\n",
    "**Overview:** Insertion sort iterates, consuming one input element each repetition, and growing a sorted output list. At each iteration, insertion sort removes one element from the input data, finds the location it belongs within the sorted list, and inserts it there. It repeats until no input elements remain.\n",
    "\n",
    "**Analysis:**\n",
    "The outer loop executes n−1 times, that's quite clear.\n",
    "\n",
    "But the number of times the inner-loop is executed depends on the input:\n",
    "-  In best-case scenario, the array is already sorted and (a[j] > X) is always false. So no shifting of data is necessary and the inner loop runs in O(1).\n",
    "- In worst-case scenario, the array is reverse sorted and (a[j] > X) is always true. Insertion always occur at the front of the array and the inner loop runs in O(n).\n",
    "\n",
    "Thus, the best-case time is O(n × 1) = O(n) and the worst-case time is O(n × n) = O($n^{2}$).\n",
    "\n",
    "**psuedocode:**\n",
    "```\n",
    "mark first element as sorted\n",
    "\n",
    "for each unsorted element X\n",
    "  'extract' the element X\n",
    "\n",
    "  for j = lastSortedIndex down to 0\n",
    "    if current element j > X\n",
    "      move sorted element to the right by 1\n",
    "    break loop and insert X here\n",
    "```\n",
    "\n",
    "**Implementation of Insertion Sort:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 8, 12, 25, 41]\n"
     ]
    }
   ],
   "source": [
    "def insertion_sort(arr):\n",
    "    \n",
    "    # For every index in array (except the element at the first index, as it is already sorted in itself)\n",
    "    for i in range(1,len(arr)):\n",
    "        \n",
    "        # Set current values and position\n",
    "        currentvalue = arr[i]\n",
    "        position = i\n",
    "        \n",
    "        # Sorted Sublist\n",
    "        while position>0 and arr[position-1]>currentvalue:\n",
    "            \n",
    "            arr[position]=arr[position-1] #Shift elements to right until a smaller element to X is encountered\n",
    "            position = position-1\n",
    "\n",
    "        arr[position]=currentvalue\n",
    "        \n",
    "def exec():\n",
    "    arr =[3,5,4,6,8,1,2,12,41,25]\n",
    "    insertion_sort(arr)\n",
    "    print(arr)\n",
    "exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
