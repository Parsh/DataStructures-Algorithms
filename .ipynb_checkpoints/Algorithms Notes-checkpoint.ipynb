{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "## Introduction to Algorithms\n",
    "\n",
    ">Algorithm is a step-by-step procedure, which defines a set of instructions to be executed in a certain order to get the desired output. Algorithms are generally created independent of underlying languages, i.e. an algorithm can be implemented in more than one programming language.\n",
    "\n",
    "\n",
    "![](./Images-Algorithms/AlgorithmAnalogy.png \"Program vs Algorithm\")\n",
    "Note: For more on models of computation (Random Access Machine and Pointer Machine) refer to the MIT 6.006 digital notes (Lecture 2).\n",
    "\n",
    "**Psuedocode:** Pseudo code is an informal high-level description of the operating principle of an algorithm. It uses the structural conventions of a normal programming language, but is intended for human reading rather than machine reading. As we know that all programming languages share basic code constructs like loops (for, while), flow-control (if-else), etc. These common constructs can be used, in psuedocode, to write an algorithm.\n",
    "\n",
    "**Fundamental Idea behind algorithm design:**\n",
    "![](./Images-Algorithms/FundamentalIdea.png \"Fundamental Idea in Algorithm Design\")\n",
    "Algorithmic Design Patterns like Divide and Conquer, Dynamic Programming and Greedy Algorithms uses this fundamental idea to design apt algorithms.\n",
    "\n",
    "\n",
    "\n",
    "**Categories of algorithms:**\n",
    "\n",
    "From the data structure point of view, following are some important categories of algorithms:\n",
    "\n",
    "- **Search** − Algorithm to search an item in a data structure.\n",
    "- **Insert** − Algorithm to insert item in a data structure.\n",
    "- **Update** − Algorithm to update an existing item in a data structure.\n",
    "- **Delete** − Algorithm to delete an existing item from a data structure.\n",
    "- **Sort** − Algorithm to sort items in a certain order.\n",
    "\n",
    "![](./Images-Algorithms/WhyAlgorithms.png )\n",
    "\n",
    "\n",
    "**Characteristics of an Algorithm:**\n",
    "\n",
    "Not all procedures can be called an algorithm. An algorithm should have the following characteristics:\n",
    "\n",
    ">**Input** − An algorithm should have 0 or more well-defined inputs.\n",
    "\n",
    ">**Output** − An algorithm should have 1 or more well-defined outputs, and should match the desired output.\n",
    "\n",
    ">**Unambiguous** − Algorithm should be clear and unambiguous. Each of its steps (or phases), and their inputs/outputs should be clear and must lead to only one meaning.\n",
    "\n",
    ">**Finiteness** − Algorithms must terminate after a finite number of steps, an infinite procedure isn't regarded as an algorithm.\n",
    "\n",
    ">**Feasibility** − Should be feasible with the available resources.\n",
    "\n",
    ">**Independent** − An algorithm should have step-by-step directions, which should be independent of any programming code.\n",
    "\n",
    "Reference: [Data Structures and Algorithms](https://www.tutorialspoint.com/data_structures_algorithms/algorithms_basics.htm)\n",
    "\n",
    "**Analysis of Algorithms:**\n",
    "\n",
    "Efficiency of an algorithm can be analyzed at two different stages:\n",
    "\n",
    ">**A Priori Analysis: ** This is a theoretical analysis of an algorithm i.e. a pre-implementation analysis. Efficiency of an algorithm is measured by performing Asyptotic analysis whereby assuming that all other factors, for example, processor speed, are constant and have no effect on the implementation.\n",
    "\n",
    ">**A Posterior Analysis: ** This is an empirical analysis of an algorithm i.e. a post-implementation analysis. The selected algorithm is implemented using programming language. This is then executed on target computer machine. In this analysis, actual statistics like running time and space required, are collected.\n",
    "\n",
    "\n",
    "### Algorithm Complexity:\n",
    "Recommended Read: [Algorithmic Complexity](https://www.cs.cmu.edu/~adamchik/15-121/lectures/Algorithmic%20Complexity/complexity.html) <br>\n",
    "Time Complexity Analysis Concise Video Series: [Time Complexity](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI9HK8YPVBjElbLbI3ufctn)\n",
    "\n",
    "\n",
    "Some algorithms are more efficient than others. We would prefer to chose an efficient algorithm, so it would be nice to have metrics for comparing algorithm efficiency.\n",
    "\n",
    "The complexity of an algorithm is a function describing the efficiency of the algorithm in terms of the amount of data (inputs) the algorithm must process. Usually there are natural units for the domain and range of this function. There are two main complexity measures of the efficiency of an algorithm:\n",
    "\n",
    ">**Time complexity** is a function describing the amount of time an algorithm takes in terms of the amount of input to the algorithm. \"Time\" can mean the number of memory accesses performed, the number of comparisons between integers, the number of times some inner loop is executed, or some other natural unit related to the amount of real time the algorithm will take. We try to keep this idea of time separate from \"wall clock\" time, since many factors unrelated to the algorithm itself can affect the real time (like the language used, type of computing hardware, proficiency of the programmer, optimization in the compiler, etc.). It turns out that, if we chose the units wisely, all of the other stuff doesn't matter and we can get an independent measure of the efficiency of the algorithm.\n",
    "\n",
    ">**Space complexity** is a function describing the amount of memory (space) an algorithm takes in terms of the amount of input to the algorithm. We often speak of \"extra\" memory needed, not counting the memory needed to store the input itself. Again, we use natural (but fixed-length) units to measure this. We can use bytes, but it's easier to use, say, number of integers used, number of fixed-sized structures, etc. In the end, the function we come up with will be independent of the actual number of bytes needed to represent the unit. Space complexity is sometimes ignored because the space used is minimal and/or obvious, but sometimes it becomes as important an issue as time.\n",
    "For example, we might say \"this algorithm takes n2 time,\" where n is the number of items in the input. Or we might say \"this algorithm takes constant extra space,\" because the amount of extra memory needed doesn't vary with the number of items processed.\n",
    "\n",
    "For both time and space, we are interested in the asymptotic complexity of the algorithm: When n (the number of items of input) goes to infinity, what happens to the performance of the algorithm?\n",
    "\n",
    "The term analysis of algorithms is used to describe approaches to the study of the performance of algorithms. In this course we will perform the following types of analysis:\n",
    "- the **worst-case runtime complexity** of the algorithm is the function defined by the maximum number of steps taken on any instance of size a.\n",
    "- the **best-case runtime complexity** of the algorithm is the function defined by the minimum number of steps taken on any instance of size a.\n",
    "- the **average case runtime complexity** of the algorithm is the function defined by an average number of steps taken on any instance of size a.\n",
    "- the **amortized runtime complexity** of the algorithm is the function defined by a sequence of operations applied to the input of size a and averaged over time.\n",
    "\n",
    "**Asymptotic Analysis:**\n",
    "\n",
    "It is the most effective way of doint a priori analysis. Notations used in asymptotic analysis are refered to as asymptotic notations. Asymptotic Notations could be regarded as a language that allow us to analyze an algorithm’s running time by identifying its behavior as the input size for the algorithm increases. This is also known as an algorithm’s growth rate. Does the algorithm suddenly become incredibly slow when the input size grows? Does it mostly maintain its quick run time as the input size increases? Asymptotic Notation gives us the ability to answer these questions. <br>\n",
    "Recommended  Read: [Asymptotic Notation](https://learnxinyminutes.com/docs/asymptotic-notation/)<br>\n",
    "Alternative Read: [Asymptotic Notation](https://www.geeksforgeeks.org/analysis-of-algorithms-set-3asymptotic-notations/)\n",
    "\n",
    "Ques: Why do we use Big-O to represent the complexity in most cases and not Big-Omega or Theta? <br>\n",
    "Ans: Because in domain of computer science we take a pessimistic view, as we cann't assume anything about the input therefore  at all times we are concerned with the worst case complexity of our algorithm, i.e., we want to find out the upper bound for our algorithm which communicates the maximum/utmost rate of growth of our algorithm's runtime/space-consumption in terms of growth of the input size.\n",
    "\n",
    "Note: **Asymptotic runtimes are functions of the input size**, i.e., they communicate how the runtime(time or space) would scale as the input size grows larger and larger. Asymptotic runtime is a handy tool for comparing/analyzing algorithms before implementation, however, they aren't exact rather provide an approximate idea of the runtimes. Therefore, for exact runtime of the algorithm over a given architecture is done using the Posterior analysis.\n",
    "\n",
    "**Growth Rate (w.r.t. input size) of various function**\n",
    "\n",
    "![](./Images-Algorithms/GrowthRate.png \"Growth rate of different functions\")\n",
    "\n",
    "### Complexity (Big-O) for various Data Structures and Algorithms\n",
    "\n",
    "**Goodness Scale: **![](./Images-Algorithms/GoodnessScale.png \"Goodness Scale\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-DataStructures.png \"Big-O complexity for Data Structures\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Searching.png \"Big-O complexity for Searching\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Sorting.png \"Big-O complexity for Sorting\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Heaps.png \"Big-O complexity for Heaps\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Graphs.png \"Big-O complexity for Graphs\")\n",
    "\n",
    "\n",
    "\n",
    "Responsive Cheat Sheet: [Big O and Growth Rate Cheat Sheets](http://cooervo.github.io/Algorithms-DataStructures-BigONotation/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Algorithm Design Paradigms\n",
    "\n",
    "### Introduction\n",
    "\n",
    ">**Algorithm Design Paradigms:** General approaches to the construction of efficient solutions to problems.\n",
    "\n",
    "Such methods are of interest because:\n",
    "\n",
    "- They provide templates suited to solving a broad range of diverse problems.\n",
    "- They can be translated into common control and data structures provided by most high-level languages.\n",
    "- The temporal and spatial requirements of the algorithms which result can be precisely analyzed.\n",
    "\n",
    "Although more than one technique may be applicable to a specific problem, it is often the case that an algorithm constructed by one approach is clearly superior to equivalent solutions built using alternative techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Brute Force\n",
    "\n",
    ">Brute force is a straightforward approach to solve a problem based on the problem’s statement and definitions of the concepts involved. It is considered as one of the easiest approach to apply and is useful for solving small – size instances of a problem.\n",
    "\n",
    "Some examples of brute force algorithms are: \n",
    "- Computing an (a > 0, n a nonnegative integer) by multiplying a x a x… x a\n",
    "- Computing n!\n",
    "- Selection sort \n",
    "- Bubble sort\n",
    "- Sequential search \n",
    "- Exhaustive search: Traveling Salesman Problem, Knapsack problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Greedy Algorithms \"take what you can get now\" strategy\n",
    "\n",
    ">The solution is constructed through a sequence of steps, each expanding a partially constructed solution obtained so far. At each step the choice must be locally optimal – this is the central point of this technique. Greedy techniques are mainly used to solve optimization problems. They do not always give the best solution.\n",
    " \n",
    "Example:\n",
    "\n",
    "Consider the knapsack problem with a knapsack of capacity 10 and 4 items given by the < weight:value > pairs: < 5:6 >, < 4:3 >, < 3: 5 >, < 3: 4 >. The greedy algorithm will choose item 1 < 5:6 > and then item 3 < 3:5 >, as it tries to get local optimals, resulting in total value 11(which is not optimal globally), while the optimal solution is to choose items 2, 3, and 4 thus obtaining total value 12.\n",
    "\n",
    "Note: It has been proven that greedy algorithms for the minimal spanning tree, the shortest paths, and Huffman codes  always give the optimal solution.\n",
    "\n",
    "More Examples: \n",
    "\n",
    "- Minimal spanning tree\n",
    "- Shortest distance in graphs\n",
    "- Greedy algorithm for the Knapsack problem\n",
    "- The coin exchange problem\n",
    "- Huffman trees for optimal encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Divide-and-Conquer, Decrease-and-Conquer\n",
    "These are methods of designing algorithms that (informally) proceed as follows:\n",
    "\n",
    ">Given an instance of the problem to be solved, split this into several smaller sub-instances (of the same problem), independently solve each of the sub-instances and then combine the sub-instance solutions so as to yield a solution for the original instance.\n",
    "\n",
    "Note: With the divide-and-conquer method the size of the problem instance is reduced by a factor (e.g. half the input size), while with the decrease-and-conquer method the size is reduced by a constant.\n",
    "\n",
    "Examples of divide-and-conquer algorithms:\n",
    "\n",
    "- Computing an (a > 0, n a nonnegative integer) by recursion\n",
    "- Binary search in a sorted array (recursion)\n",
    "- Mergesort algorithm, Quicksort algorithm  (recursion)\n",
    "- The algorithm for solving the fake coin problem (recursion)\n",
    "\n",
    "Examples of decrease-and-conquer algorithms:\n",
    "\n",
    "- Insertion sort\n",
    "- Topological sorting\n",
    "- Binary Tree traversals: inorder, preorder and postorder (recursion)\n",
    "- Computing the length of the longest path in a binary tree (recursion)\n",
    "- Computing Fibonacci numbers (recursion)\n",
    "- Reversing a queue (recursion)\n",
    "- Warshall’s algorithm (recursion)\n",
    "\n",
    "**The issues here are two:**\n",
    "\n",
    "- How to solve the sub-instance?\n",
    "- How to combine the obtained solutions?\n",
    "\n",
    "**Addressing issues:**\n",
    "- The answer to the second question depends on the nature of the problem.\n",
    "- In most cases the answer to the first question is: using the same method(break it down further). <br> Here another very important issue arises: when to stop decreasing the problem instance, i.e. what is the minimal instance of the given problem and how to solve it?\n",
    "\n",
    "When we use recursion, the solution of the minimal instance is called “terminating condition”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dynamic Programming\n",
    "One disadvantage of using Divide-and-Conquer is that the process of recursively solving separate sub-instances can result in the same computations being performed repeatedly since identical sub-instances may arise.\n",
    "\n",
    ">The idea behind dynamic programming is to avoid this pathology by obviating the requirement to calculate the same quantity twice. The method usually accomplishes this by maintaining a table of sub-instance results i.e. memoizing the resultls of the sub-problems.\n",
    "\n",
    "Dynamic Programming is a Bottom-Up Technique in which the smallest sub-instances are explicitly solved first and the results of these used to construct solutions to progressively larger sub-instances.\n",
    "\n",
    "In contrast, Divide-and-Conquer is a Top-Down Technique which logically progresses from the initial instance down to the smallest sub-instance via intermediate sub-instances.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Fibonacci numbers computed by iteration.\n",
    "- Warshall’s algorithm implemented by iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Transform-and-Conquer\n",
    "These methods work as two-stage procedures. First, the problem is modified to be more amenable to solution. In the second stage the problem is solved.\n",
    "\n",
    "Types of problem modifications:\n",
    "\n",
    "- **Problem simplification** e.g. presorting <br>\n",
    "  Example: consider the problem of finding the two closest numbers in an array of numbers.\n",
    "      Brute force solution: O(n2)\n",
    "      Transform and conquer solution: O(nlogn)\n",
    "           Presort the array – O(nlogn)\n",
    "           Scan the array comparing the differences - O(n)\n",
    "- **Change in the representation** <br>\n",
    "    Example: AVL trees guarantee O(nlogn) search time\n",
    "- **Problem reduction** <br>\n",
    "    Example: least common multiple\n",
    "        lcm(m,n) = (m*n)/ gcd(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
