{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "## Introduction to Algorithms\n",
    "\n",
    ">Algorithm is a step-by-step procedure, which defines a set of instructions to be executed in a certain order to get the desired output. Algorithms are generally created independent of underlying languages, i.e. an algorithm can be implemented in more than one programming language.\n",
    "\n",
    "\n",
    "![](./Images-Algorithms/AlgorithmAnalogy.png \"Program vs Algorithm\")\n",
    "Note: For more on models of computation (Random Access Machine and Pointer Machine) refer to the MIT 6.006 digital notes (Lecture 2).\n",
    "\n",
    "**Psuedocode:** Pseudo code is an informal high-level description of the operating principle of an algorithm. It uses the structural conventions of a normal programming language, but is intended for human reading rather than machine reading. As we know that all programming languages share basic code constructs like loops (for, while), flow-control (if-else), etc. These common constructs can be used, in psuedocode, to write an algorithm.\n",
    "\n",
    "**Fundamental Idea behind algorithm design:**\n",
    "![](./Images-Algorithms/FundamentalIdea.png \"Fundamental Idea in Algorithm Design\")\n",
    "Algorithmic Design Patterns like Divide and Conquer, Dynamic Programming and Greedy Algorithms uses this fundamental idea to design apt algorithms.\n",
    "\n",
    "\n",
    "\n",
    "**Categories of algorithms:**\n",
    "\n",
    "From the data structure point of view, following are some important categories of algorithms:\n",
    "\n",
    "- **Search** − Algorithm to search an item in a data structure.\n",
    "- **Insert** − Algorithm to insert item in a data structure.\n",
    "- **Update** − Algorithm to update an existing item in a data structure.\n",
    "- **Delete** − Algorithm to delete an existing item from a data structure.\n",
    "- **Sort** − Algorithm to sort items in a certain order.\n",
    "\n",
    "![](./Images-Algorithms/WhyAlgorithms.png )\n",
    "\n",
    "\n",
    "**Characteristics of an Algorithm:**\n",
    "\n",
    "Not all procedures can be called an algorithm. An algorithm should have the following characteristics:\n",
    "\n",
    ">**Input** − An algorithm should have 0 or more well-defined inputs.\n",
    "\n",
    ">**Output** − An algorithm should have 1 or more well-defined outputs, and should match the desired output.\n",
    "\n",
    ">**Unambiguous** − Algorithm should be clear and unambiguous. Each of its steps (or phases), and their inputs/outputs should be clear and must lead to only one meaning.\n",
    "\n",
    ">**Finiteness** − Algorithms must terminate after a finite number of steps, an infinite procedure isn't regarded as an algorithm.\n",
    "\n",
    ">**Feasibility** − Should be feasible with the available resources.\n",
    "\n",
    ">**Independent** − An algorithm should have step-by-step directions, which should be independent of any programming code.\n",
    "\n",
    "Reference: [Data Structures and Algorithms](https://www.tutorialspoint.com/data_structures_algorithms/algorithms_basics.htm)\n",
    "\n",
    "## Analysis of Algorithms:\n",
    "Highly Recommended Read (Have a profound look at each topic): [Analysis of Algorithms](https://www.geeksforgeeks.org/fundamentals-of-algorithms/#AnalysisofAlgorithms)\n",
    "\n",
    "Efficiency of an algorithm can be analyzed at two different stages:\n",
    "\n",
    ">**A Priori Analysis: ** This is a theoretical analysis of an algorithm i.e. a pre-implementation analysis. Efficiency of an algorithm is measured by performing Asyptotic analysis whereby assuming that all other factors, for example, processor speed, are constant and have no effect on the implementation.\n",
    "\n",
    ">**A Posterior Analysis: ** This is an empirical analysis of an algorithm i.e. a post-implementation analysis. The selected algorithm is implemented using programming language. This is then executed on target computer machine. In this analysis, actual statistics like running time and space required, are collected.\n",
    "\n",
    "\n",
    "### Algorithm Complexity:\n",
    "Recommended Read: [Algorithmic Complexity](https://www.cs.cmu.edu/~adamchik/15-121/lectures/Algorithmic%20Complexity/complexity.html) <br>\n",
    "Time Complexity Analysis Concise Video Series: [Time Complexity](https://www.youtube.com/playlist?list=PL2_aWCzGMAwI9HK8YPVBjElbLbI3ufctn)\n",
    "\n",
    "\n",
    "Some algorithms are more efficient than others. We would prefer to chose an efficient algorithm, so it would be nice to have metrics for comparing algorithm efficiency.\n",
    "\n",
    "The complexity of an algorithm is a function describing the efficiency of the algorithm in terms of the amount of data (inputs) the algorithm must process. Usually there are natural units for the domain and range of this function. There are two main complexity measures of the efficiency of an algorithm:\n",
    "\n",
    ">**Time complexity** is a function describing the amount of time an algorithm takes in terms of the amount of input to the algorithm. \"Time\" can mean the number of memory accesses performed, the number of comparisons between integers, the number of times some inner loop is executed, or some other natural unit related to the amount of real time the algorithm will take. We try to keep this idea of time separate from \"wall clock\" time, since many factors unrelated to the algorithm itself can affect the real time (like the language used, type of computing hardware, proficiency of the programmer, optimization in the compiler, etc.). It turns out that, if we chose the units wisely, all of the other stuff doesn't matter and we can get an independent measure of the efficiency of the algorithm.\n",
    "\n",
    ">**Space complexity** is a function describing the amount of memory (space) an algorithm takes in terms of the amount of input to the algorithm. We often speak of \"extra\" memory needed, not counting the memory needed to store the input itself. Again, we use natural (but fixed-length) units to measure this. We can use bytes, but it's easier to use, say, number of integers used, number of fixed-sized structures, etc. In the end, the function we come up with will be independent of the actual number of bytes needed to represent the unit. Space complexity is sometimes ignored because the space used is minimal and/or obvious, but sometimes it becomes as important an issue as time.\n",
    "For example, we might say \"this algorithm takes n2 time,\" where n is the number of items in the input. Or we might say \"this algorithm takes constant extra space,\" because the amount of extra memory needed doesn't vary with the number of items processed.\n",
    "\n",
    "For both time and space, we are interested in the asymptotic complexity of the algorithm: When n (the number of items of input) goes to infinity, what happens to the performance of the algorithm?\n",
    "\n",
    "The term analysis of algorithms is used to describe approaches to the study of the performance of algorithms. In this course we will perform the following types of analysis:\n",
    "- the **worst-case runtime complexity** of the algorithm is the function defined by the maximum number of steps taken on any instance of size a.\n",
    "- the **best-case runtime complexity** of the algorithm is the function defined by the minimum number of steps taken on any instance of size a.\n",
    "- the **average case runtime complexity** of the algorithm is the function defined by an average number of steps taken on any instance of size a.\n",
    "- the **amortized runtime complexity** of the algorithm is the function defined by a sequence of operations applied to the input of size a and averaged over time.\n",
    "\n",
    "**Asymptotic Analysis:**\n",
    "\n",
    "It is the most effective way of doint a priori analysis. Notations used in asymptotic analysis are refered to as asymptotic notations. Asymptotic Notations could be regarded as a language that allow us to analyze an algorithm’s running time by identifying its behavior as the input size for the algorithm increases. This is also known as an algorithm’s growth rate. Does the algorithm suddenly become incredibly slow when the input size grows? Does it mostly maintain its quick run time as the input size increases? Asymptotic Notation gives us the ability to answer these questions. <br>\n",
    "Recommended  Read: [Asymptotic Notation](https://learnxinyminutes.com/docs/asymptotic-notation/)<br>\n",
    "Alternative Read: [Asymptotic Notation](https://www.geeksforgeeks.org/analysis-of-algorithms-set-3asymptotic-notations/)\n",
    "\n",
    "Ques: Why do we use Big-O to represent the complexity in most cases and not Big-Omega or Theta? <br>\n",
    "Ans: Because in domain of computer science we take a pessimistic view, as we cann't assume anything about the input therefore  at all times we are concerned with the worst case complexity of our algorithm, i.e., we want to find out the upper bound for our algorithm which communicates the maximum/utmost rate of growth of our algorithm's runtime/space-consumption in terms of growth of the input size.\n",
    "\n",
    "Note: **Asymptotic runtimes are functions of the input size**, i.e., they communicate how the runtime(time or space) would scale as the input size grows larger and larger. Asymptotic runtime is a handy tool for comparing/analyzing algorithms before implementation, however, they aren't exact rather provide an approximate idea of the runtimes. Therefore, for exact runtime of the algorithm over a given architecture is done using the Posterior analysis.\n",
    "\n",
    "**Growth Rate (w.r.t. input size) of various function**\n",
    "\n",
    "![](./Images-Algorithms/GrowthRate.png \"Growth rate of different functions\")\n",
    "\n",
    "### Complexity (Big-O) for various Data Structures and Algorithms\n",
    "\n",
    "**Goodness Scale: **![](./Images-Algorithms/GoodnessScale.png \"Goodness Scale\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-DataStructures.png \"Big-O complexity for Data Structures\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Searching.png \"Big-O complexity for Searching\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Sorting.png \"Big-O complexity for Sorting\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Heaps.png \"Big-O complexity for Heaps\")\n",
    "\n",
    "![](./Images-Algorithms/BigO-Graphs.png \"Big-O complexity for Graphs\")\n",
    "\n",
    "\n",
    "\n",
    "Responsive Cheat Sheet: [Big O and Growth Rate Cheat Sheets](http://cooervo.github.io/Algorithms-DataStructures-BigONotation/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Algorithm Design Paradigms\n",
    "\n",
    "### Introduction\n",
    "\n",
    ">**Algorithm Design Paradigms:** General approaches to the construction of efficient solutions to problems.\n",
    "\n",
    "Such methods are of interest because:\n",
    "\n",
    "- They provide templates suited to solving a broad range of diverse problems.\n",
    "- They can be translated into common control and data structures provided by most high-level languages.\n",
    "- The temporal and spatial requirements of the algorithms which result can be precisely analyzed.\n",
    "\n",
    "Although more than one technique may be applicable to a specific problem, it is often the case that an algorithm constructed by one approach is clearly superior to equivalent solutions built using alternative techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Brute Force\n",
    "\n",
    ">Brute force is a straightforward approach to solve a problem based on the problem’s statement and definitions of the concepts involved. It is considered as one of the easiest approach to apply and is useful for solving small – size instances of a problem.\n",
    "\n",
    "Some examples of brute force algorithms are: \n",
    "- Computing an (a > 0, n a nonnegative integer) by multiplying a x a x… x a\n",
    "- Computing n!\n",
    "- Selection sort \n",
    "- Bubble sort\n",
    "- Sequential search \n",
    "- Exhaustive search: Traveling Salesman Problem, Knapsack problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Greedy Algorithms \"take what you can get now\" strategy\n",
    "\n",
    ">The solution is constructed through a sequence of steps, each expanding a partially constructed solution obtained so far. At each step the choice must be locally optimal – this is the central point of this technique. Greedy techniques are mainly used to solve optimization problems. They do not always give the best solution.\n",
    " \n",
    "Example:\n",
    "\n",
    "Consider the knapsack problem with a knapsack of capacity 10 and 4 items given by the < weight:value > pairs: < 5:6 >, < 4:3 >, < 3: 5 >, < 3: 4 >. The greedy algorithm will choose item 1 < 5:6 > and then item 3 < 3:5 >, as it tries to get local optimals, resulting in total value 11(which is not optimal globally), while the optimal solution is to choose items 2, 3, and 4 thus obtaining total value 12.\n",
    "\n",
    "Note: It has been proven that greedy algorithms for the minimal spanning tree, the shortest paths, and Huffman codes  always give the optimal solution.\n",
    "\n",
    "More Examples: \n",
    "\n",
    "- Minimal spanning tree\n",
    "- Shortest distance in graphs\n",
    "- Greedy algorithm for the Knapsack problem\n",
    "- The coin exchange problem\n",
    "- Huffman trees for optimal encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Divide-and-Conquer, Decrease-and-Conquer\n",
    "These are methods of designing algorithms that (informally) proceed as follows:\n",
    "\n",
    ">Given an instance of the problem to be solved, split this into several smaller sub-instances (of the same problem), independently solve each of the sub-instances and then combine the sub-instance solutions so as to yield a solution for the original instance.\n",
    "\n",
    "Note: With the divide-and-conquer method the size of the problem instance is reduced by a factor (e.g. half the input size), while with the decrease-and-conquer method the size is reduced by a constant.\n",
    "\n",
    "Examples of divide-and-conquer algorithms:\n",
    "\n",
    "- Computing an (a > 0, n a nonnegative integer) by recursion\n",
    "- Binary search in a sorted array (recursion)\n",
    "- Mergesort algorithm, Quicksort algorithm  (recursion)\n",
    "- The algorithm for solving the fake coin problem (recursion)\n",
    "\n",
    "Examples of decrease-and-conquer algorithms:\n",
    "\n",
    "- Insertion sort\n",
    "- Topological sorting\n",
    "- Binary Tree traversals: inorder, preorder and postorder (recursion)\n",
    "- Computing the length of the longest path in a binary tree (recursion)\n",
    "- Computing Fibonacci numbers (recursion)\n",
    "- Reversing a queue (recursion)\n",
    "- Warshall’s algorithm (recursion)\n",
    "\n",
    "**The issues here are two:**\n",
    "\n",
    "- How to solve the sub-instance?\n",
    "- How to combine the obtained solutions?\n",
    "\n",
    "**Addressing issues:**\n",
    "- The answer to the second question depends on the nature of the problem.\n",
    "- In most cases the answer to the first question is: using the same method(break it down further). <br> Here another very important issue arises: when to stop decreasing the problem instance, i.e. what is the minimal instance of the given problem and how to solve it?\n",
    "\n",
    "When we use recursion, the solution of the minimal instance is called “terminating condition”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dynamic Programming\n",
    "One disadvantage of using Divide-and-Conquer is that the process of recursively solving separate sub-instances can result in the same computations being performed repeatedly since identical sub-instances may arise.\n",
    "\n",
    ">The idea behind dynamic programming is to avoid this pathology by obviating the requirement to calculate the same quantity twice. The method usually accomplishes this by maintaining a table of sub-instance results i.e. memoizing the resultls of the sub-problems.\n",
    "\n",
    "Dynamic Programming is a Bottom-Up Technique in which the smallest sub-instances are explicitly solved first and the results of these used to construct solutions to progressively larger sub-instances.\n",
    "\n",
    "In contrast, Divide-and-Conquer is a Top-Down Technique which logically progresses from the initial instance down to the smallest sub-instance via intermediate sub-instances game.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Fibonacci numbers computed by iteration.\n",
    "- Warshall’s algorithm implemented by iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Backtracking and branch-and-bound: generate and test methods\n",
    "The method is used for state-space search problems. State-space search problems are problems, where the problem representation consists of:\n",
    "- initial state\n",
    "- goal state(s)\n",
    "- a set of intermediate states\n",
    "- a set of operators that transform one state into another. Each operator has preconditions and postconditions.\n",
    "- a cost function – evaluates the cost of the operations (optional)\n",
    "- a utility function – evaluates how close is a given state to the goal state (optional)\n",
    "\n",
    "\n",
    ">The solving process solution is based on the construction of a **state-space tree**, whose nodes represent states, the root represents the initial state, and one or more leaves are goal states. Each edge is labeled with some operator. \n",
    "\n",
    ">If a node *b* is obtained from a node *a* as a result of applying the operator *O*, then *b* is a child of *a* and the edge from *a* to *b* is labeled with *O*.<br>\n",
    "The solution is obtained by searching the tree until a goal state is found.\n",
    "\n",
    "\n",
    "**Backtracking uses depth-first search** usually without cost function. <br>The main algorithm is as follows:\n",
    "\n",
    ">1. Store the initial state in a stack\n",
    ">2. While the stack is not empty, do:\n",
    "\n",
    "    >>1. Read a node from the stack.\n",
    "    >>2. While there are available operators do:\n",
    "    \n",
    "        >>>1. Apply an operator to generate a child\n",
    "        >>>2. If the child is a goal state – stop\n",
    "        >>>3. If it is a new state, push the child into the stack\n",
    "        \n",
    "The utility function is used to tell how close is a given state to the goal state and whether a given state may be considered a goal state.<br>\n",
    "If no children can be generated from a given node, then we **backtrack** – read the next node from the stack.\n",
    "\n",
    "Example: The following problems can be solved using state-space search techniques:\n",
    "1. A farmer has to move a goat, a cabbage and a wolf from one side of a river to the other side using a small boat. The boat can carry only the farmer and one more object (either the goat, or the cabbage, or the wolf). If the farmer leaves the goat with the wolf alone, the wolf would kill the goat. If the goat is alone with the cabbage, it will eat the cabbage. How can the farmer move all his property safely to the other side of the river?\"<br> <br>\n",
    "\n",
    "2. You are given two jugs, a 4-gallon one and a 3-gallon one. Neither has any measuring markers on it. There is a tap that can be used to fill the jugs with water. How can you get exactly 2 gallons of water into the 4-gallon jug?\n",
    "\n",
    "We have to decide:\n",
    "\n",
    "1. representation of the problem state, initial and final states\n",
    "2. representation of the actions available in the problem, in terms of how they change the problem state.\n",
    "\n",
    "**Branch-and-bound:**\n",
    ">Branch and bound is used when we can evaluate each node using the cost and utility functions. At each step we choose the best node to proceed further. Branch-and bound algorithms are implemented using a priority queue. The state-space tree is built in a breadth-first manner.\n",
    "\n",
    "Example: The 8-puzzle problem. The cost function is the number of moves. The utility function evaluates how close is a given state of the puzzle to the goal state, example counting how many tiles are not in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Transform-and-Conquer\n",
    "These methods work as two-stage procedures. First, the problem is modified to be more amenable to solution. In the second stage the problem is solved.\n",
    "\n",
    "Types of problem modifications:\n",
    "\n",
    "- **Problem simplification** e.g. presorting <br>\n",
    "  Example: consider the problem of finding the two closest numbers in an array of numbers.\n",
    "      Brute force solution: O(n2)\n",
    "      Transform and conquer solution: O(nlogn)\n",
    "           Presort the array – O(nlogn)\n",
    "           Scan the array comparing the differences - O(n)\n",
    "- **Change in the representation** <br>\n",
    "    Example: AVL trees guarantee O(nlogn) search time\n",
    "- **Problem reduction** <br>\n",
    "    Example: least common multiple\n",
    "        lcm(m,n) = (m*n)/ gcd(m,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Genetic Algorithms\n",
    "Genetic algorithms (GAs) are used mainly for optimization problems for which the exact algorithms are of very low efficiency.\n",
    "\n",
    "GAs search for good solutions to a problem from among a (large) number of possible solutions. The current set of possible solutions is used to generate a new set of possible solution.\n",
    "\n",
    ">They start with an initial set of possible solutions, and at each step they do the following:\n",
    "\n",
    ">1. evaluate the current set of solutions (current generation)\n",
    ">2. choose the best of them to serve as “parents” for the new generation, and construct the new generation.\n",
    "\n",
    ">The loop runs until a specified condition becomes true, e.g. a solution is found that satisfies the criteria for a “good” solution, or the number of iterations exceeds a given value, or no improvement ahs been recorded when evaluation the solutions.\n",
    "\n",
    "Key issues here are:\n",
    "\n",
    ">1. How large to be the **size of a population** so that there is sufficient diversity? Usually the size is determined through trial-and-error experiments.<br><br>\n",
    "\n",
    ">2. How to represent the solutions so that the representations can be manipulated to obtain a new solution? One approach is to represent the solutions as strings of characters (could be binary strings) and to use various types of “crossover” (explained below) to obtain a new set of solutions. The strings are usually called **“chromosomes”**.<br><br>\n",
    "\n",
    ">3. how to evaluate a solution?. The function used to evaluate a solution is called **“fitness function”** and it depends on the nature of the problem.<br><br>\n",
    "\n",
    ">4. How to manipulate the representations in order to construct a new solution? The method that is characteristic of GAs is to combine two or more representations by taking substrings of each of them to construct a new solution. This operation is called **“crossover”**.<br><br>\n",
    "\n",
    ">5. How to choose the individual solutions that will serve as parents for the new generation? The process of choosing parents is called **“selection”**. Various methods have been experimented here. It seems that the choice is dependent on the nature of the problem and the chosen representation. One method is to choose parents with a probability proportional to their fitness. This method is called “roulette wheel selection”.<br><br>\n",
    "\n",
    ">6. How to avoid convergence to a set of equal solutions? The approach here is to change randomly the representation of a solution. If the representation is a bit string we can flip bits. This operation is called **“mutation”**.<br><br>\n",
    "\n",
    "Using the terminology above, we can outline the algorithms to obtain one generation:\n",
    "\n",
    "- compute the fitness of each chromosome\n",
    "- select parents based on the fitness value and a selection strategy\n",
    "- perform crossover to obtain new chromosomes\n",
    "- perform mutation on the new chromosomes (with fixed or random probability)\n",
    "\n",
    "Examples: \n",
    "\n",
    "- The knapsack problem solved with GAs\n",
    "- The traveling salesman problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Usually a given problem can be solved using various approaches however it is not wise to settle for the first that comes to mind. More often than not, some approaches result in much more efficient solutions than others.    Consider again the Fibonacci numbers computed recursively using the decrease-and-conquer approach, and computed by iterations using dynamic programming. In the first case the complexity is O($2^{n}$), while in the second case the complexity is O(n). \n",
    "On the other hand, consider sorting based on decrease-and-conquer (insertion sort) and brute force sorting. For almost sorted files insertion sort will give almost linear complexity, while brute force sorting algorithms have quadratic complexity.\n",
    "\n",
    "The basic question here is: How to choose the approach? <br>\n",
    "First, by understanding the problem and <br>\n",
    "Second, by knowing various problems and how they are solved using different approaches. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P vs NP\n",
    "Highly Recommended Watch: [P vs NP](https://www.youtube.com/watch?v=YX40hbAHx3s)\n",
    "\n",
    "We have seen efficient algorithms to solve complex problems, like shortest path, Euler graph, minimum spanning tree, etc. Those were all success stories of algorithm designers. Now is the time to ponder upon their failures.\n",
    "\n",
    "![](./Images-Algorithms/P VS NP.png \"P vs NP\")\n",
    "\n",
    "**Can all computational problems be solved by a computer?** <br>\n",
    "There are computational problems that can not be solved by algorithms even with unlimited time. For example Turing Halting problem (Given a program and an input, whether the program will eventually halt when run with that input, or will run forever). Alan Turing proved that general algorithm to solve the halting problem for all possible program-input pairs cannot exist.\n",
    "\n",
    "Note: Turing Machine is a mathematical model of a hypothetical computing machine which can use a predefined set of rules to determine a result from a set of input variables.\n",
    "\n",
    "**Status of NP Complete problems** is another failure story, NP complete problems are problems whose status is unknown. No polynomial time algorithm has yet been discovered for any NP complete problem, nor has anybody yet been able to prove that no polynomial-time algorithm exist for any of them. The interesting part is, if any one of the NP complete problems can be solved in polynomial time, then all of them can be solved (cuz they are reducable, in some way, to one another).\n",
    "\n",
    "### What are NP, P, NP-complete and NP-Hard problems?\n",
    "\n",
    ">**P** is set of problems that can be solved by a deterministic Turing machine in Polynomial time.\n",
    "\n",
    ">**NP** is set of decision problems that can be solved by a Non-deterministic Turing Machine in Polynomial time. P is subset of NP (any problem that can be solved by deterministic machine in polynomial time can also be solved by non-deterministic machine in polynomial time).\n",
    "Informally, NP is set of decision problems which can be solved by a polynomial time via a “Lucky Algorithm”, a magical algorithm that always makes a right guess among the given set of choices \n",
    "\n",
    ">**NP-complete** problems are the hardest problems in NP set.  A decision problem L is NP-complete if:\n",
    "1. L is in NP (Any given solution for NP-complete problems can be verified quickly, but there is no efficient known solution).\n",
    "2. Every problem in NP is reducible to L in polynomial time (Reduction is defined below).\n",
    "\n",
    ">A problem is **NP-Hard** if it follows property 2 mentioned above, doesn’t need to follow property 1. Therefore, NP-Complete set is also a subset of NP-Hard set.\n",
    "\n",
    "\n",
    "**Decision vs Optimization Problems**\n",
    "\n",
    "NP-completeness applies to the realm of decision problems. It was set up this way because it’s easier to compare the difficulty of decision problems than that of optimization problems. In reality, though, being able to solve a decision problem in polynomial time will often permit us to solve the corresponding optimization problem in polynomial time (using a polynomial number of calls to the decision problem). So, discussing the difficulty of decision problems is often really equivalent to discussing the difficulty of optimization problems. \n",
    "\n",
    "For example, consider the vertex cover problem (Given a graph, find out the minimum sized vertex set that covers all edges). It is an optimization problem. Corresponding decision problem is, given undirected graph G and k, is there a vertex cover of size k?\n",
    "\n",
    "**What is Reduction?**\n",
    "\n",
    ">Let L1 and L2 be two decision problems. Suppose algorithm A2 solves L2. That is, if y is an input for L2 then algorithm A2 will answer Yes or No depending upon whether y belongs to L2 or not.\n",
    "The idea is to find a transformation from L1 to L2 so that the algorithm A2 can be part of an algorithm A1 to solve L1.\n",
    "\n",
    "Learning reduction in general is very important. For example, if we have library functions to solve certain problem and if we can reduce a new problem to one of the solved problems, we save a lot of time. Consider the example of a problem where we have to find minimum product path in a given directed graph where product of path is multiplication of weights of edges along the path. If we have code for Dijkstra’s algorithm to find shortest path, we can take log of all weights and use Dijkstra’s algorithm to find the minimum product path rather than writing a fresh code for this new problem.\n",
    "\n",
    "**How to prove that a given problem is NP complete?**\n",
    "\n",
    "From the definition of NP-complete, it appears impossible to prove that a problem L is NP-Complete.  By definition, it requires us to that show every problem in NP is polynomial time reducible to L. Fortunately, there is an alternate way to prove it. The idea is to take a known NP-Complete problem and reduce it to L. If polynomial time reduction is possible, we can prove that L is NP-Complete by transitivity of reduction (If a NP-Complete problem is reducible to L in polynomial time, then all problems are reducible to L in polynomial time).\n",
    "\n",
    "**What was the first problem proved as NP-Complete?**\n",
    "\n",
    "There must be some first NP-Complete problem proved by definition of NP-Complete problems.  SAT (Boolean satisfiability problem) is the first NP-Complete problem proved.\n",
    "\n",
    "It is always useful to know about NP-Completeness even for engineers. Suppose you are asked to write an efficient algorithm to solve an extremely important problem for your company. After a lot of thinking, you can only come up exponential time approach which is impractical. If you don’t know about NP-Completeness, you can only say that I could not come with an efficient algorithm. If you know about NP-Completeness and prove that the problem as NP-complete, you can proudly say that the polynomial time solution is unlikely to exist. If there is a polynomial time solution possible, then that solution solves a big problem of computer science many scientists have been trying for years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
